# ğŸ“Š Social Media Analytics Pipeline
This repository demonstrates a complete end-to-end data pipeline for ingesting, processing, and visualizing social media data using Snowflake.

ğŸ”§ Key Components

Python Scripts

Connect to social media APIs
Extract and transform data
Load data files into a Snowflake staging area

SnowSQL Scripts

Set up automated data ingestion using Snowpipe
Configure Streams, Tasks, and Stored Procedures
Manage real-time processing from raw data to final target tables

Streamlit Dashboard
Visualize the processed data in an interactive dashboard
Enables quick insights from the ingested social media content

âœ… What This Project Shows
This repo serves as a blueprint for building a fully automated data pipeline within Snowflake, from API integration to analytics-ready dashboards. It's a practical example of how modern data engineering tools can be orchestrated to support real-time social media analytics.

---

## ğŸ“Œ Setup & Installation

### Install Dependencies
Ensure you have Python installed, then run:

```
pip install -r requirements.txt
```

ğŸš€ Steps to Run the Project
1ï¸âƒ£ Deploy Snowflake Database & Objects
Before running any scripts, set up the database, tables, and necessary objects in Snowflake:
-- Run this in Snowflake
```
Snowflake/Snowflake_setup.sql
```

2ï¸âƒ£ Generate JSON Data
Run the JSON data generator script manually:
```
python src/json_gen.py
```
Or deploy it via Kubernetes:
```
kubectl apply -f kube_deployment.yaml
```
This will generate JSON files to be uploaded to Snowflake.

3ï¸âƒ£ Files upload to Snowflake
Once JSON files are generated, sf_file_upload.py is called to upload them.

This script loads data from JSON files into Snowflake.

4ï¸âƒ£ Validate Data
To ensure data integrity, run the validation SQL script inside Snowflake:
-- Run this in Snowflake
```
Snowflake/Validation_script.sql
```

5ï¸âƒ£ Visualize Data Using Streamlit
Launch the analytics dashboard:
```
streamlit run src/Snowflake_dashboard.py
```
This will open an interactive web-based dashboard to explore the data.

ğŸ“‚ Project Structure
```
ğŸ“¦ Project Root
â”œâ”€â”€ ğŸ“‚ config                  # Configurations (e.g., Snowflake credentials)
â”‚   â”œâ”€â”€ config.ini
â”œâ”€â”€ ğŸ“‚ json                    # JSON data files
â”‚   â”œâ”€â”€ data_XXXX.json
â”œâ”€â”€ ğŸ“‚ src                     # Source scripts
â”‚   â”œâ”€â”€ Snowflake_dashboard.py  # Streamlit dashboard
â”‚   â”œâ”€â”€ json_gen.py             # Generates JSON data
â”‚   â”œâ”€â”€ sf_file_upload.py       # Uploads JSON data to Snowflake
â”œâ”€â”€ ğŸ³ dockerfile               # Docker container setup
â”œâ”€â”€ ğŸ“„ kube_deployment.yaml     # Kubernetes deployment config
â”œâ”€â”€ ğŸ“‚ Snowflake                # SQL scripts for Snowflake setup & validation
â”‚   â”œâ”€â”€ Snowflake_setup.sql
â”‚   â”œâ”€â”€ Validation_script.sql
â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â””â”€â”€ ğŸ“„ README.md                # Project documentation
```
ğŸ› ï¸ Future Enhancements
Automate validation checks in Python.

Expand dashboard with filters and export options.

ğŸ’¡ Notes
Ensure Snowflake credentials are set up in config/config.ini.

Kubernetes deployment requires a configured cluster.

Streamlit should be run locally or deployed as a web app.

This README provides **clear step-by-step instructions** for setup, execution, and troubleshooting. 
Let me know if you'd like any modifications! ğŸš€
Happy coding! ğŸš€
